{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "import spacy\n",
    "import spacy\n",
    "#import neuralcoref\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7ffdefb89748>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./102106057/01_nltk.txt\n",
      "./102106057/02_nltk.txt\n",
      "./102106057/03_nltk.txt\n",
      "./102106057/04_nltk.txt\n",
      "./102106057/05_nltk.txt\n",
      "./102106057/06_nltk.txt\n",
      "./102106057/07_nltk.txt\n",
      "./102106057/08_nltk.txt\n",
      "./102106057/09_nltk.txt\n",
      "./102106057/10_nltk.txt\n",
      "./102106057/11_nltk.txt\n",
      "./102106057/12_nltk.txt\n",
      "./102106057/13_nltk.txt\n",
      "./102106057/14_nltk.txt\n",
      "./102106057/15_nltk.txt\n",
      "./102106057/16_nltk.txt\n",
      "./102106057/17_nltk.txt\n",
      "./102106057/18_nltk.txt\n",
      "./102106057/19_nltk.txt\n",
      "./102106057/20_nltk.txt\n",
      "./102106057/21_nltk.txt\n",
      "./102106057/22_nltk.txt\n",
      "./102106057/23_nltk.txt\n",
      "./102106057/24_nltk.txt\n",
      "./102106057/25_nltk.txt\n",
      "./102106057/26_nltk.txt\n",
      "./102106057/27_nltk.txt\n",
      "./102106057/28_nltk.txt\n",
      "./102106057/29_nltk.txt\n",
      "./102106057/30_nltk.txt\n",
      "./102106057/31_nltk.txt\n",
      "./102106057/32_nltk.txt\n",
      "./102106057/33_nltk.txt\n",
      "./102106057/34_nltk.txt\n",
      "./102106057/35_nltk.txt\n",
      "./102106057/36_nltk.txt\n",
      "./102106057/37_nltk.txt\n",
      "./102106057/38_nltk.txt\n",
      "./102106057/39_nltk.txt\n",
      "./102106057/40_nltk.txt\n",
      "./103101003/01_nltk.txt\n",
      "./103101003/02_nltk.txt\n",
      "./103101003/03_nltk.txt\n",
      "./103101003/04_nltk.txt\n",
      "./103101003/05_nltk.txt\n",
      "./103101003/06_nltk.txt\n",
      "./103101003/07_nltk.txt\n",
      "./103101003/08_nltk.txt\n",
      "./103101003/09_nltk.txt\n",
      "./103101003/10_nltk.txt\n",
      "./103101003/11_nltk.txt\n",
      "./103101003/12_nltk.txt\n",
      "./103101003/13_nltk.txt\n",
      "./103101003/14_nltk.txt\n",
      "./103101003/15_nltk.txt\n",
      "./103101003/16_nltk.txt\n",
      "./103101003/17_nltk.txt\n",
      "./103101003/18_nltk.txt\n",
      "./103101003/19_nltk.txt\n",
      "./103101003/20_nltk.txt\n",
      "./103101003/21_nltk.txt\n",
      "./103101003/22_nltk.txt\n",
      "./103101003/23_nltk.txt\n",
      "./103101003/24_nltk.txt\n",
      "./103101003/25_nltk.txt\n",
      "./103101003/26_nltk.txt\n",
      "./103102012/01_nltk.txt\n",
      "./103102012/02_nltk.txt\n",
      "./103102012/03_nltk.txt\n",
      "./103102012/04_nltk.txt\n",
      "./103102012/05_nltk.txt\n",
      "./103102012/06_nltk.txt\n",
      "./103102012/07_nltk.txt\n",
      "./103102012/08_nltk.txt\n",
      "./103102012/09_nltk.txt\n",
      "./103102012/10_nltk.txt\n",
      "./103102012/11_nltk.txt\n",
      "./103102012/12_nltk.txt\n",
      "./103102012/13_nltk.txt\n",
      "./103102012/14_nltk.txt\n",
      "./103102012/15_nltk.txt\n",
      "./103102012/16_nltk.txt\n",
      "./103102012/17_nltk.txt\n",
      "./103102012/18_nltk.txt\n",
      "./103102012/19_nltk.txt\n",
      "./103102012/20_nltk.txt\n",
      "./103102012/21_nltk.txt\n",
      "./103102012/22_nltk.txt\n",
      "./103102012/23_nltk.txt\n",
      "./103102012/24_nltk.txt\n",
      "./103102012/25_nltk.txt\n",
      "./103102012/26_nltk.txt\n",
      "./103102012/27_nltk.txt\n",
      "./103102012/28_nltk.txt\n",
      "./103102012/29_nltk.txt\n",
      "./103102012/30_nltk.txt\n",
      "./103102012/31_nltk.txt\n",
      "./103102012/32_nltk.txt\n",
      "./103102012/33_nltk.txt\n",
      "./103102012/34_nltk.txt\n",
      "./103102012/35_nltk.txt\n",
      "./103102012/36_nltk.txt\n",
      "./103102012/37_nltk.txt\n",
      "./103102012/38_nltk.txt\n",
      "./103102012/39_nltk.txt\n",
      "./103102012/40_nltk.txt\n",
      "./103104044/01_nltk.txt\n",
      "./103104044/02_nltk.txt\n",
      "./103104044/03_nltk.txt\n",
      "./103104044/04_nltk.txt\n",
      "./103104044/05_nltk.txt\n",
      "./103104044/06_nltk.txt\n",
      "./103104044/07_nltk.txt\n",
      "./103104044/08_nltk.txt\n",
      "./103104044/09_nltk.txt\n",
      "./103104044/10_nltk.txt\n",
      "./103104044/11_nltk.txt\n",
      "./103104044/12_nltk.txt\n",
      "./103104044/13_nltk.txt\n",
      "./103104044/14_nltk.txt\n",
      "./103104044/15_nltk.txt\n",
      "./103104044/16_nltk.txt\n",
      "./103104044/17_nltk.txt\n",
      "./103104044/18_nltk.txt\n",
      "./103104044/19_nltk.txt\n",
      "./103104044/20_nltk.txt\n",
      "./103104044/21_nltk.txt\n",
      "./103104044/22_nltk.txt\n",
      "./103104044/23_nltk.txt\n",
      "./103104044/24_nltk.txt\n",
      "./103104044/25_nltk.txt\n",
      "./103104044/26_nltk.txt\n",
      "./103104044/27_nltk.txt\n",
      "./103104044/28_nltk.txt\n",
      "./103104044/29_nltk.txt\n",
      "./103104044/30_nltk.txt\n",
      "./103104044/31_nltk.txt\n",
      "./103104044/32_nltk.txt\n",
      "./103104044/33_nltk.txt\n",
      "./103104044/34_nltk.txt\n",
      "./103104044/35_nltk.txt\n",
      "./103104044/36_nltk.txt\n",
      "./103104044/37_nltk.txt\n",
      "./103104044/38_nltk.txt\n",
      "./103104044/39_nltk.txt\n",
      "./103104044/40_nltk.txt\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob('./*/*_nltk.txt') :\n",
    "    print(file)\n",
    "    file_handle = open(file,'r')\n",
    "    discourse = file_handle.read()\n",
    "    \n",
    "    #list_of_tokens = list()\n",
    "    doc = nlp(discourse)\n",
    "    \n",
    "    sentence_list = list()\n",
    "    for token in doc :\n",
    "        sentence_list.append([token.text])\n",
    "        \n",
    "    for cluster in doc._.coref_clusters :\n",
    "        mention_count = 0\n",
    "        for mention in cluster.mentions :\n",
    "            #print(mention.start)\n",
    "            #print(type(mention.end))\n",
    "            if mention_count == 0 :\n",
    "                occurance = 'first occurance'\n",
    "            else :\n",
    "                occurance = 'next occurance'\n",
    "            first_token = sentence_list[mention.start][0]\n",
    "            sentence_list[mention.start].insert(0,'{' + first_token)\n",
    "            sentence_list[mention.start].pop(1)\n",
    "            \n",
    "            last_token = sentence_list[mention.end - 1][0]\n",
    "            sentence_list[mention.end - 1].insert(0,last_token + '}')\n",
    "            sentence_list[mention.end - 1].pop(1)\n",
    "            \n",
    "            sentence_list[mention.end - 1].append('(' + mention._.coref_cluster.main.text + ')' + '<' + occurance + ',' + str(mention._.coref_cluster.main.start) + ',' + str(mention._.coref_cluster.main.end) + '>')\n",
    "            #print(type(mention._.coref_cluster.main.text))\n",
    "            \n",
    "            mention_count += 1\n",
    "    \n",
    "    processed_sentence = list()\n",
    "    for token in sentence_list :\n",
    "        complete_token = ' '.join(token)\n",
    "        processed_sentence.append(complete_token)\n",
    "\n",
    "    corefered_discourse = ' '.join(processed_sentence)\n",
    "    #corefered_discourse = ' '.join(list_of_tokens)\n",
    "    \n",
    "    write_file = open('{}.COREFERED'.format(file),'w',encoding='utf-8')\n",
    "    write_file.write(discourse)\n",
    "    \n",
    "    write_file.write(\"\\n\\n\")\n",
    "    \n",
    "    write_file.write(corefered_discourse)\n",
    "    write_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
